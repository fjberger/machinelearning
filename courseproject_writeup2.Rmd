Class: Practical Machine Learning - Course Project Writeup
========================================================
```{r}
library(AppliedPredictiveModeling)
library(caret)
```

# First Steps

* Data are read in, original training set is split into training and validation set

```{r}
originalTrainingData<-read.csv("/home/florian/ArbeitsflÃ¤che/Data Science/Machine Learning/Course Project/pml-training.csv", header = TRUE)
```

* splitting training into training and validation set
```{r}
set.seed(2612)
trainIndex = createDataPartition(originalTrainingData$classe, p = 0.50,list=FALSE)
training = originalTrainingData[trainIndex,]
validation = originalTrainingData[-trainIndex,]
```

# Preprocessing
* The training set was limited to the variables with no missings, this was alos needed to be able to predict on the test set.
```{r}
na_count <-sapply(originalTrainingData, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count$var<-rownames(na_count)
keep<-na_count[na_count$na_count==0,2]
training2<-subset(training,select=keep)
```

* The data were pre-processed (centering and scaling, afterwards PCA was appplied, this yielded 27 PC to explain 95% of the variance)

``` {r}
trans <- preProcess(training2[,-59], 
                   method=c("center", 
                            "scale", "pca"))
trainingPC <- predict(trans, training2)

validationPC <-  predict(trans, validation)
```



# Model Fitting
* Several methods for model training were assessed (Penalized Multinomial Regression,Linear Discriminant Analysis, Naive BAyes, Penalized Discriminant Analysis, Shrinkage Discriminant Analysis, Random Forest. Linear discriminant analyses yielded best results with a accuracy on the validation set of 0.99

# Predicting on the test set

* Finally predictions on the test set where carried out.
